version: "2.3"
services:
  kneel:
    runtime: nvidia
    image: "miptmloulu/kneel:gpu"
    ports:
      - "5000:5000"
    volumes:
      - type: bind
        source: ../snapshots_release_kneel # The snapshots are stored in the root directory
        target: /snapshots/
        read_only: true
      - type: bind
        source: ../logs
        target: /logs/
    entrypoint: ["python", "-u", "-m", "kneel.inference.app",
       "--lc_snapshot_path", "/snapshots/lext-devbox_2019_07_14_16_04_41",
      "--hc_snapshot_path", "/snapshots/lext-devbox_2019_07_14_19_25_40",
      "--refine", "True", "--mean_std_path", "/snapshots/mean_std.npy",
      "--deploy", "True", "--device", "cuda", "--port", "5000", "--logs", "/logs/kneel-gpu.log"]
  deepknee-backend:
    runtime: nvidia
    depends_on:
      - kneel
    build:
      context: ../
      dockerfile: ./docker/Dockerfile.gpu
    ports:
      - "5001:5001"
    volumes:
      - type: bind
        source: ../snapshots_knee_grading/ # The snapshots are stored in the root directory
        target: /snapshots/
        read_only: true
      - type: bind
        source: ../logs
        target: /logs/
    environment:
      - KNEEL_ADDR=http://kneel:5000
    entrypoint: ["python", "-m", "ouludeepknee.inference.app",
                   "--snapshots_path", "/snapshots/",
                   "--device", "cuda", "--deploy", "True",
                 "--port", "5001", "--logs", "/logs/deepknee-gpu.log"]
